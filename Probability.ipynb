{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence\n",
    "\n",
    "**Indepent Events**\n",
    "\n",
    "$A$ and $B$ are independent if knowing whether $A$ occured gives no information abouth whether $B$ occured . More formally , $A$ and $B$(which have nonzero probability) are independent if and only if one of the following statements hold:\n",
    "\n",
    "$$P(A\\cap B) = P(A)P(B)$$\n",
    "\n",
    "**!! only when $A$ and $B$ are independent,otherwise $A\\subset B$!!**\n",
    "\n",
    "$$P(A\\mid B) = P(A)$$\n",
    "\n",
    "$$P(B\\mid A) = P(B)$$\n",
    "\n",
    "**Conditional independence**\n",
    "\n",
    "$A$ and $B$ are conditionally independent given $C$ if $P(A\\cap B\\mid C) =P(A\\mid C)P(B\\mid C)$\n",
    "\n",
    "**Conditional independence does not imply independence, and independence does not imply conditional independence.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De Morgan`s Law\n",
    "\n",
    "useful identity  that can make calculating probabilities of unions easier by relating them to intersections, and vice versa\n",
    "Analogous results hold with more then two sets\n",
    "\n",
    "$$(A_{1}\\cup A_{2}\\cup \\ldots \\cup A_{n})^{c}=A_{1}^{c}\\cap A_{2}^{c}\\cap \\ldots \\cap A_{n}^{c}$$\n",
    "\n",
    "$$(A_{1}\\cap A_{2}\\cap \\ldots  \\cap A_{n})^{c}=A_{1}^{c}\\cup A_{2}^{c}\\cup \\ldots \\cup A_{n}^{c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint, Marginal and Conditional \n",
    "\n",
    "**Joint Probability** $P(A\\cap B)$ or $P(A,B)$ - Probability of $A$ and $B$\n",
    "\n",
    "**Marginal (Uncoditional) Probability** $P(A)$ - Probability of A\n",
    "\n",
    "**Conditional Probability** - $P(A\\mid B) = P(A,B)/P(B)$ - Probability of $A$ given that $B$ occured\n",
    "\n",
    "**Conditional Probability *is* Probability** - $P(A\\mid B)$ is a probability function for any fixed $B$. Any theorem that holds for probability also holds for conditional probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of an Intersections or Union\n",
    "\n",
    "**Intersections via conditioning** \n",
    "\n",
    "$$P(A,B) = P(A)P(B\\mid A)$$\n",
    "$$P(A,B,C) = P(A)P(B\\mid A)P(C\\mid A,B)$$\n",
    "\n",
    "**Unions via Inclusion-Exclusion**\n",
    "\n",
    "$$P(A\\cup B) = P(A)+P(B)-P(A\\cap B)$$\n",
    "\n",
    "$$P(A\\cup B\\cup C) = P(A)+P(B)+P(C) - P(A\\cap B)- P(A\\cap C) - P(B\\cap C)+P(A\\cap B\\cap C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "\n",
    "if $A$ and $B$ are events with $P(B)>0$, then the *conditional probability* of $A$ given $B$, denoted by $P\\:(A\\mid B)$ is defined as\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(A\\cap B)}{P(B)}$$\n",
    "\n",
    "Here  $A$ is the event which uncertainty we want to update , and $B$ is the evidence we observe (or we want to treat as given). We call  $P(A)$ the *prior* probability of $A$ and $P(A\\mid B) the *posterior* probability of $A$ ('prior' means before updating based on the evidence, and the 'posterior ' means after updating based on the evidence).\n",
    "\n",
    "$P(A\\mid B)$ is the probability of $A$ given evidence $B$,      **NOT** THE PROBABILITY OF SOME ENTITY CALLED $A\\mid B$\n",
    "\n",
    "\n",
    "When we calculate conditional probabilities, we do not assume  whether one event causes other, **we are considering what information observing one event provides about another event.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='prob_img/cond_intuituion_pebble_world.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 2.3.1\n",
    "\n",
    "For any events $A$ and $B$ with positive probabilities\n",
    "\n",
    "$$P\\:(A\\cap B) = P(B)\\:P(A\\mid B)= P(A)\\:P(B\\mid A)$$\n",
    "\n",
    "- just slightly differently written definition of conditional probability\n",
    "  - but can be useful because it can help us find $P\\:(A\\cap B)$ without going back to definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.3.2**\n",
    "\n",
    "For any events $A_{1},\\ldots,A_{n}$ with positive probabilities\n",
    "\n",
    "$$P(A_{1},A_{2},\\ldots,A_{n})= P(A_{1})P(A_{2}\\mid A_{1})P({A_{3}\\mid A_{1},A_{2}})\\ldots P(A_{n}\\mid A_{1},\\ldots,A_{n-1}) $$\n",
    "\n",
    "The commas denote intersections. For example , $P(A_{3}\\mid A_{1},A_{2})$ is the probability that A_{3} occurs, given that both $A_{1}$ and $A_{2}$ occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.3.3 (Bayes Rule)**\n",
    "\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A)P(A)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odds of an event A**\n",
    "\n",
    "$odds(A)=P(A)/P(A^{c})$\n",
    "\n",
    "for example, if $P(A)=2/3$, we say the odds in favor of $A$ are 2 to 1(2:1)\n",
    "\n",
    "To convert from odds back to probability:\n",
    "\n",
    "$P(A)=odds(A)/(1+odds(A))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.3.5**\n",
    "\n",
    "**Odds form of Bayes rule**\n",
    "\n",
    "For any events $A$ and $B$ with positive probabilities, the odds of $A$ after conditioning on $B$ are:\n",
    "\n",
    "$$\\frac{P(A\\mid B)}{P(A^{c}\\mid B)}=\\frac{P(B\\mid A)}{P(B\\mid A^{c})}\\frac{P(A)}{P(A^{c})}$$\n",
    "\n",
    "In words this says, that the *posterior* *odds* $P(A\\mid B)/P(A^{c}\\mid B)$ are equal to *prior* *odds* $P(A)/P(A^{c})$ times the factor $P(B\\mid A)/P(B\\mid A^{c})$,which is known in statitistics as *likelihood* *ratio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.3.4 (Law of total probability (LOTP))**\n",
    "\n",
    "\n",
    "$$P(B)=\\sum_{i=1}^{n}P(B\\mid A_{i})P(A_{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since the $A_{i}$ form the partition of $S$, we can decompose $B$ as\n",
    "\n",
    "$$P(B)=P(B\\cap A_{1})\\cup P(B\\cap A_{2})\\cup \\ldots \\cup P(B\\cap A_{n})$$\n",
    "\n",
    "<img src='prob_img\\lotp.png'>\n",
    "\n",
    "**The law of total probability tells us that to get the unconditional probability of , we can divide the sample space into disjoint slices , find the conditional probability of within each of the slices, then take a weighted sum of the conditional probabilities, where the weights are the probabilities.** \n",
    "\n",
    "**The choice of how to divide up the sample space is crucial: a well-chosen partition will reduce a complicated problem into simpler pieces, whereas a poorly chosen partition will only exacerbate our problems, requiring us to calculate difficult probabilities instead of just one!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thinking Conditionally is condition for thinking\n",
    "\n",
    "**How to solve a problem ?**\n",
    "\n",
    "1.) Try simple and extreme cases\n",
    "\n",
    "2.) Break up  problem into simpler pieces (LOTP)\n",
    "\n",
    "**Hazards:**\n",
    "\n",
    "- Prosecutors fallacy:\n",
    "  - $P($Innocence$\\mid\\:$Evidence$)$ vs $P($Evidence$\\mid\\:$Innocence$)$\n",
    "- Prior vs Posterior:\n",
    "  - Prior = before we have evidence\n",
    "  - Posterior = after we have evidence\n",
    "- Confusing independence vs conditional indpendence\n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probabilities are probabilities \n",
    "\n",
    "When we condition on arbitrary event $E$, we update our beliefs to be consistent with, effectively putting ourselves in a universe where we know that $E$ occured.\n",
    "\n",
    "Within our new universe,however, laws of probability operates just as before.\n",
    "\n",
    "**Conditional probability satisfies all the properties of probability!**\n",
    "\n",
    "Therefore,any of the results we have derived about probability are still valid if we replace all uncoditional probabilities with probabilities conditional on $E$. In particular:\n",
    "\n",
    "- Conditional probabilities are between 0 and 1\n",
    "- $P(S\\mid E) = 1$,$P(\\varnothing\\mid E)= 0$\n",
    "- if $A_{1},A_{2},\\ldots$ are disjoint,then $P(\\bigcup_{j=1}^{\\infty}A_{j}\\mid E)=\\sum_{j=1}^{\\infty}P(A_{j}\\mid E)$\n",
    "- $P(A^{c}\\mid E) = 1 - P(A\\mid E)$\n",
    "- Inclusion-Exclusion : $P(A\\cup B\\mid E)=P(A\\mid E)+P(B\\mid E) - P(A\\cap B\\mid E)$\n",
    "\n",
    "When we write $P(A\\mid E)$, it does **not** mean that $A\\mid E$ is an event and we are taking it`s probability; $A\\mid E$ is not event!.\n",
    "\n",
    "Rather, $P(\\cdotp \\mid E)$ is a probability function  which assigns probabilities in accordance with the knowledge that E has occured, and $P(\\cdotp)$ is a different probability function  which assigns probabilities without regard for whether $E$ has occured or not. When we take an event $A$ and plug it into the $P(\\cdotp)$ function , we`ll get another number, $P(A\\mid E)$, which incorporates the information(if any) provided by knowing that $E$ occured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes Rule with extra conditioning**\n",
    "\n",
    "Provided that $P(A\\cap E) > 0$ and $P(B\\cap E)> 0$, we have\n",
    "\n",
    "$$P(A\\mid B,E) = \\frac{P(B\\mid A,E)\\:P(A\\mid E)}{P(B\\mid E)}$$\n",
    "\n",
    "\n",
    "**LOTP with extra conditioning**\n",
    "\n",
    "Let $A_{1},\\ldots,A_{n}$ be a partition of S. Provided that $P(A_{i}\\cap E)> 0$ for all *i*, we have :\n",
    "\n",
    "$$P(B\\mid E)=\\sum_{i=1}^{n}P(B\\mid A_{i},E)\\:P(A_{i}\\mid E)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
