{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '3'>**Parameters** :  $\\theta_{0},\\theta_{1},\\ldots,\\theta_{n}$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> $$J (\\theta_{0},\\theta_{1},\\ldots,\\theta_{n}) = \\frac{1}{2m}\\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2 $$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Notation : </font>\n",
    "\n",
    "<font size=\"3\">$n$ = number of features\n",
    "\n",
    "$x^{(i)}$ = input (features) of $i^{th}$ training example\n",
    "\n",
    "$x_j^{(i)}$ = value of feature $j$ in $i^{th}$ training example</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-amwm\"><br>Size (feet2)</th>\n",
    "    <th class=\"tg-amwm\"><br>Number of Bedrooms<br></th>\n",
    "    <th class=\"tg-amwm\"><br>Number of floors</th>\n",
    "    <th class=\"tg-amwm\"><br>Age of home <br>   (years)<br></th>\n",
    "    <th class=\"tg-amwm\"><br> Price ( $1000)<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\"><br>2104</td>\n",
    "    <td class=\"tg-0lax\">5</td>\n",
    "    <td class=\"tg-0lax\">1</td>\n",
    "    <td class=\"tg-0lax\">45</td>\n",
    "    <td class=\"tg-0lax\">460</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">1416<br></td>\n",
    "    <td class=\"tg-0lax\">3</td>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">40</td>\n",
    "    <td class=\"tg-0lax\">232</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">1534</td>\n",
    "    <td class=\"tg-0lax\">3</td>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">30</td>\n",
    "    <td class=\"tg-0lax\">315</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">852</td>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">1</td>\n",
    "    <td class=\"tg-0lax\">36</td>\n",
    "    <td class=\"tg-0lax\">178</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '3' > $n$ = 4\n",
    "\n",
    "$x^{(2)} = \\begin{bmatrix}\n",
    "    1416 \\\\\n",
    "    3 \\\\\n",
    "    2 \\\\\n",
    "    40 \\\\\n",
    "    \\end{bmatrix}$\n",
    "\n",
    "$x^{(2)}_3$ = 2 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font size = '5'> Hypothesis for single feature: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"4\" > $h_{\\theta}( x ) = \\theta_0 + \\theta_{1}x$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font size = '5'> Hypothesis for n features: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"4\" > $h_{\\theta}( x ) = \\theta_0 + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n}$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For convenience of notation define** $x_{0} = 1$         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x = \\begin{bmatrix}\n",
    "    x_{0} \\\\\n",
    "    x_{1} \\\\\n",
    "    x_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{n} \\\\\n",
    "    \\end{bmatrix}$ <font size = '4'> $\\in \\mathbb{R}^{n+1} $</font> $ \\:\\: \\theta = \\begin{bmatrix}\n",
    "    \\theta_{0} \\\\\n",
    "    \\theta_{1} \\\\\n",
    "    \\theta_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_{n} \\\\\n",
    "    \\end{bmatrix}$ <font size = '4'> $\\in \\mathbb{R}^{n+1} $</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"4\" > $h_{\\theta}( x ) = \\theta_{0}x_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n} = \\theta^{T}x$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '4'> $  \\theta^{T} = \\begin{bmatrix}\n",
    "    \\theta_{0}& \n",
    "    \\theta_{1}& \n",
    "    \\theta_{2}&\n",
    "    \\dotsm &\n",
    "    \\theta_{n} \n",
    "    \\end{bmatrix}$  </font>  $x = \\begin{bmatrix}\n",
    "    x_{0} \\\\\n",
    "    x_{1} \\\\\n",
    "    x_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{n} \\\\\n",
    "    \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for  Multiple Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'>**Parameters** :  $\\theta$ ( n+1 dimensional vector ) \n",
    "\n",
    "$\\nabla_{\\theta}J =\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial \\theta_{0}} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_{0}} \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{n+1}$  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Gradient** **Descent**\n",
    "\n",
    "\n",
    "$\\theta := \\theta -\\alpha \\nabla_{\\theta}J$\n",
    "\n",
    "$\\theta \\in \\mathbb{R}^{n+1}$ & $\\nabla_{\\theta}J \\in \\mathbb{R}^{n+1}$\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'>\n",
    "$F \\cdot \\mathbb{R}^{m\\:x\\:n}->\\mathbb{R}$ \n",
    "\n",
    "$f(A)$\n",
    "\n",
    "$\\nabla_{a}f(A) = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial A_{11}}\\dotsm \\frac{\\partial f}{\\partial A_{1n}} \\\\\n",
    "\\vdots  \\ddots  \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial A_{n1}}\\dotsm \\frac{\\partial f}{\\partial A_{mn}} \\\\\n",
    "\\end{bmatrix}$ \n",
    " \n",
    "- derivative of $f$ with respect to $A$ is itself a matrix, and the matrix contains all the partial derivatives of $f$ with the respect to the elements of $A$\n",
    "\n",
    "if $A \\in \\mathbb{R}$\n",
    "\n",
    "$tr(A)= \\sum_{i=1}^{n}A_{ii}$ = sum of diagonal elements of $A$\n",
    "\n",
    "\n",
    "Fact:\n",
    "\n",
    "$tr(AB)=tr(BA)$\n",
    "\n",
    "$tr(ABC)=tr(CAB)=tr(BCA)$\n",
    "\n",
    "$f(A)=tr(AB)$ \n",
    "\n",
    "$\\nabla_{A}tr(AB)=B^{T}$\n",
    "\n",
    "$tr(A)=tr(A^{T})$\n",
    "\n",
    "Trace of real number, is itself. ( tr(3) = 3)\n",
    "\n",
    "\n",
    "$\\nabla_{A}tr(ABA^{T}C)=CAB+C^{T}AB^{T}$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> $$J (\\theta) = \\frac{1}{2m}\\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2 $$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5' >Repeat { \n",
    "   \n",
    "   $\\theta_{j}:= \\theta_{j} - \\alpha\\frac{\\partial }{\\partial \\theta_{j}}J(\\theta) $\n",
    "\n",
    "}            (simultaneously update for every $j = (0,\\ldots,n)$\n",
    "\n",
    "$\\alpha$ = learning rate\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent in Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "**Idea**: Make sure features are on similar scale\n",
    "\n",
    "E.G. \n",
    "\n",
    "$x_{1}$ = Size (0-20000 feet$^2$)\n",
    "\n",
    "$x_{2}$ = Number of Bedrooms (1-5)  \n",
    "\n",
    "**Why ?** Gradient Descent will converge more quickly\n",
    "\n",
    "Running gradient descent on this kind of cost function can take a long time to find a global minimum\n",
    "\n",
    "$\\theta_{2}$ paramater can take a relatively large range of values, which makes contour plot of the cost function look like very tall and skinny ovals, gradient(in red) could take a long time and go back and forth to find optimal solution\n",
    "\n",
    "<img src=\"images/contour_badly.png\" />\n",
    "\n",
    "Instead if you scaled your feature, contour plot of the cost function might look like more like a circles, then the gradient can take much more  straight path and achieve optimal point much faster\n",
    "\n",
    "<img src=\"images/contour_well_scaled_cost_function.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can speed up gradient descent by having each of our input values in roughly the same range. This is because θ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.\n",
    "\n",
    "The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same.We want to avoid large ranges,small ranges or very different ranges from one another. \n",
    "\n",
    "\n",
    "Ideally:\n",
    "\n",
    "$−1 ≤ x(i)x_{(i)}x(i)​ ≤ 1$\n",
    "\n",
    "or\n",
    "\n",
    "$−0.5 ≤ x(i)x_{(i)}x(i)​ ≤ 0.5$\n",
    "\n",
    "These aren't exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.\n",
    "\n",
    "Two techniques to help with this are feature scaling and mean normalization. Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable, resulting in a new average value for the input variable of just zero. To implement both of these techniques, adjust your input values as shown in this formula:\n",
    "\n",
    "<font size = '4' > $x_i := \\dfrac{x_i - \\mu_i}{s_i}$ </font>\n",
    "\n",
    "Where $\\mu_i$ is the **average** of all the values for feature (i) and $s_{i}$ is the range of values (max - min), or $s_{i}$ is the standard deviation.\n",
    "\n",
    "Note that dividing by the range, or dividing by the standard deviation, give different results. The quizzes in this course use range - the programming exercises use standard deviation.\n",
    "\n",
    "Example: $x_i$ is housing prices with range of 100 to 2000, with a mean value of 1000. \n",
    "\n",
    "Then, $xi:=\\dfrac{price-1000}{1900}$\n",
    "\n",
    "\n",
    "**Additional scaling methods** TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot min $J(\\theta)$ vs number of iterations\n",
    "\n",
    "  - i.e. plotting J(θ) over the course of gradient descent\n",
    "  \n",
    "- if gradient descent is working, then $J(\\theta) should decrease after every iteration\n",
    "\n",
    "- Can also show if you're not making huge gains after a certain number\n",
    "  - Can apply heuristics to reduce number of iterations if need be\n",
    "  - If, for example, after 1000 iterations you reduce the parameters by nearly nothing you could chose to only run 1000 iterations in the future\n",
    "  - Make sure you don't accidentally hard-code thresholds like this in and then forget about why they're their though!\n",
    "  \n",
    "<img src=\"images/grad_descent_min_plot.png\" />\n",
    "  \n",
    "- Number of iterations varies a lot\n",
    "  - 30 iterations\n",
    "  - 3000 iterations\n",
    "  - 3000 000 iterations\n",
    "  \n",
    "Very hard to tel in advance how many iterations will be needed\n",
    "\n",
    "Can often make a guess based a plot like this after the first 100 or so iterations\n",
    "\n",
    "- Automatic convergence tests\n",
    "  - Check if J(θ) changes by a small threshold or less\n",
    "  - Choosing this threshold is hard\n",
    "  - So often easier to check for a straight line\n",
    "    - Why? - Because we're seeing the straightness in the context of the whole algorithm\n",
    "    - Could you design an automatic checker which calculates a threshold based on the systems preceding progress?\n",
    "- Checking its working\n",
    "  - If you plot J(θ) vs iterations and see the value is increasing - means you probably need a smaller α\n",
    "  - Cause is because your minimizing a function which looks like this\n",
    "  \n",
    "<img src=\"images/large_learning_rate.png\" />\n",
    "\n",
    "### Learning rate\n",
    "\n",
    "-  For sufficiently small $\\alpha$, $J(\\theta)$ should decrease on every iteration\n",
    "\n",
    "-  But if $\\alpha$ is too small, gradient descent can be slow to converge (**or even may not converge**)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and polynomial regression\n",
    "\n",
    "- it may be better to create new features based on available features, that better help predict target feature\n",
    "  - example: predicting house price > available features - length of land, width of land >> better feature -> area of land = ( length x width)\n",
    "- often, by defining new features you may get a better model\n",
    "  \n",
    "#### Polynomial regression\n",
    "\n",
    "<img src='images/polynomial_regression.png'/>\n",
    "\n",
    "<font size = '4'>$h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+\\theta_{3}x_{3}=\\theta_{0}+\\theta_{1}(size)+\\theta_{2}(size)^2+\\theta_{3}(size)^3$</font>\n",
    "\n",
    "$x_1 = (size)$\n",
    "\n",
    "$x_1 = (size)^2$\n",
    "\n",
    "$x_1 = (size)^3$\n",
    "\n",
    "- feature scaling is increasingly important due the use of exponents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation\n",
    "\n",
    "- For some linear regression problems the normal equation provides a better solution\n",
    "- So far we've been using gradient descent\n",
    "  - Iterative algorithm which takes steps to converse\n",
    "- Normal equation solves θ analytically\n",
    "  - Solve for the optimum value of theta\n",
    "- Has some advantages and disadvantages\n",
    "\n",
    "**How does it work?**\n",
    "\n",
    "- Simplified cost function\n",
    "  - $J(\\theta) = a\\theta^2+b\\theta+c$\n",
    "    - $\\theta$ is a real number\n",
    "    \n",
    "  - Cost function is a quadratic function \n",
    "  - How do you minimize this ?\n",
    "    - $\\frac{d}{d\\theta}J(\\theta)$ \n",
    "      - take derivative of $(\\theta)$ with respect to $\\theta$\n",
    "      - Set that derivative equal to 0\n",
    "      - Solve for the value of $\\theta$ which minimizes $J(\\theta)$\n",
    "      \n",
    "- For more complex problems\n",
    "  - $\\theta$ is a n+1 multidimensional vector of real numbers \n",
    "  - Normal equation formula\n",
    "    - $\\theta = (X^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Gradient Descent</th>\n",
    "    <th class=\"tg-0pky\">Normal Equation</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">Need to choose alpha</td>\n",
    "    <td class=\"tg-0pky\">No need to choose alpha</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">Needs many iterations</td>\n",
    "    <td class=\"tg-0pky\">No need to iterate</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">$O(kn^2)$      </td>\n",
    "    <td class=\"tg-0pky\">$O(n^3)$, because of need to calculate inverse $X^{T}X$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">Works well when n is large</td>\n",
    "    <td class=\"tg-0pky\">Slow if n is very large</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "- What if  $X^{T}X$ is non-invertible(degenerate,singular) ? Solution is also to use pseudo-inverse\n",
    "  - Redundant features (linearly dependent)\n",
    "  - E.G. \n",
    "    -  $x_1$ = size in feet$^2$\n",
    "    -  $x_2$ = size in m$^2$\n",
    "  - Too many features (e.g. m<=n)\n",
    "    - Delete some features or use regularization\n",
    "\n",
    "- Normal Equation in Numpy\n",
    "\n",
    "```python\n",
    "# Modules\n",
    "import numpy as np\n",
    "\n",
    "def normalEquation(X, y):\n",
    "    m = int(np.size(data[:, 1]))\n",
    "\n",
    "    # This is the feature / parameter (2x2) vector that will\n",
    "    # contain my minimized values\n",
    "    theta = []\n",
    "\n",
    "    # I create a bias_vector to add to my newly created X vector\n",
    "    bias_vector = np.ones((m, 1))\n",
    "\n",
    "    # I need to reshape my original X(m,) vector so that I can\n",
    "    # manipulate it with my bias_vector; they need to share the same\n",
    "    # dimensions.\n",
    "    X = np.reshape(X, (m, 1))\n",
    "\n",
    "    # I combine these two vectors together to get a (m, 2) matrix\n",
    "    X = np.append(bias_vector, X, axis=1)\n",
    "\n",
    "    # Normal Equation:\n",
    "    # theta = inv(X^T * X) * X^T * y\n",
    "\n",
    "    # For convenience I create a new, tranposed X matrix\n",
    "    X_transpose = np.transpose(X)\n",
    "\n",
    "    # Calculating theta\n",
    "    theta = np.linalg.inv(X_transpose.dot(X))\n",
    "    theta = theta.dot(X_transpose)\n",
    "    theta = theta.dot(y)\n",
    "\n",
    "    return theta\n",
    "\n",
    "p = normalEquation(y, X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 5\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
