{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization of Logistic Regression cost function for Neural Networks\n",
    "\n",
    "\n",
    "**Variables:**\n",
    "- L = total number of layers in the network\n",
    "- $s_l$ = number of units ( not counting bias unit) in layer l\n",
    "- K = number of output units/classes\n",
    "\n",
    "\n",
    "$h_\\theta(x)_k$ is hypotesis that results in $k^{th}$  output\n",
    "\n",
    "**Reguralized logistic regression cost function**\n",
    "\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}y^{(i)}[log(h_\\theta(x^{(i)}) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n}\\theta_{j}^{2}$$\n",
    "\n",
    "**Reguralized logistic regression cost function for neural networks**\n",
    "\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K}[y^{(i)}log(h_\\theta(x^{(i)}_k) + (1 - y^{(i)}_k)log(1 - (h_\\theta(x^{(i)})_k)] + \\frac{\\lambda}{2m} \\sum_{l= 1}^{L-1} \\sum_{i= 1}^{s_l} \\sum_{j=1}^{s_{l}+1}\n",
    " (\\theta_{j,i}^{(l)})^{2}$$\n",
    "\n",
    "**Differences**\n",
    "\n",
    "- In cost part of function \n",
    "    - we have added nested summation that loops through number of output nodes $\\sum_{k=1}^{K}$\n",
    "- In reguralization part we need to account for multiple theta matrices\n",
    "    - Number of columns in our current theta matrix is equal to the number of nodes in our current layer(including bias unit)\n",
    "    - Number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding bias unit)\n",
    "    - Same as befor with logistic regression, we square every term\n",
    "        - double sum adds up the logistic regression costs calculated for each cell in the output layer \n",
    "            - $\\sum_{i=1}^{m}\\sum_{k=1}^{K}$\n",
    "        - triple sum adds up the squares of all individual $\\theta$s in the entire network \n",
    "            - $\\sum_{l= 1}^{L-1} \\sum_{i= 1}^{s_l} \\sum_{j=1}^{s_{l}+1}$ \n",
    "        - $i$ in the triple sum does **not** refer to training example $i$\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
