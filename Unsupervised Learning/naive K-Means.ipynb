{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means\n",
    "\n",
    "\n",
    "One of the most popular algorithm for automatically grouping data in coherent subsets.\n",
    "\n",
    "The k-means algorithm is used to partition a given set of observations into a predefined amount of $k$ clusters. The algorithm starts with a random set of $k$ center-points ($\\mu$). During each update step, all observations $x$ are assigned to their nearest center-point . In the standard algorithm, only one assignment to one center is possible. If multiple centers have the same distance to the observation, a random one would be chosen.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "S_i^{(t)} = \\big \\{ x_p : \\big \\| x_p - \\mu^{(t)}_i \\big \\|^2 \\le \\big \\| x_p - \\mu^{(t)}_j \\big \\|^2 \\ \\forall j, 1 \\le j \\le k \\big\\}\n",
    "\\label{eqn:kmeans_assign_step}\n",
    "\\end{equation}\n",
    "\n",
    "Afterwards, the center-points are repositioned by calculating the mean of the assigned observations to the respective center-points .\n",
    "\n",
    "\n",
    "$$\\mu^{(t+1)}_i = \\frac{1}{|S^{(t)}_i|} \\sum_{x_j \\in S^{(t)}_i} x_j$$\n",
    "\n",
    "\n",
    "The update process reoccurs until all observations remain at the assigned center-points and therefore the center-points would not be updated anymore.\n",
    "\n",
    "\n",
    "\n",
    "1. Randomly initialize two points in the dataset called the *cluster centroids*.\n",
    "2. **Cluster assignment:** assign all examples into one of K groups based on which cluster centroid the example is closest to. \n",
    "3. **Move centroid:** compute the averages for all points inside each of the K cluster centroid groups, then move cluster centroid points to those averages.\n",
    "4. Repeat 2. and 3. until we have found clusters\n",
    "\n",
    "\n",
    "```python\n",
    "for i in range(m):\n",
    "    c[i] = index of (from 1 to K) of cluster centroid closest to x(i)\n",
    "for k in range(K):\n",
    "    mu[k] = average(mean) of points assigned to cluster k\n",
    "```\n",
    "\n",
    "In **first for loop** we make vector $c$ where $c^{(i)}$ represents the centroid assigned to example $x^{(i)}$,\n",
    "   \n",
    "- $c^{(i)}= argmin_k||x^{(i)} - \\mu_k||^2$\n",
    "so each $c^{(i)}$ contains the index of centroid that has minimal distance to $x^{(i)}$\n",
    "\n",
    "    - It is convention to square right hand side, which makes the function we are trying to minimize more sharply increasing.\n",
    "        - helps reduce computation load because Euclidean distance requires a square root, but it is canceled\n",
    "\n",
    "The **second for-loop** moves each centroid to average of its group.\n",
    "\n",
    "$\\mu_k = \\dfrac{1}{n}[x^{(k_1)} + x^{(k_2)} + \\dots + x^{(k_n)}] \\in \\mathbb{R}^n$\n",
    "\n",
    "Where each of $x^{(k_1)},x^{(k_2)},\\dots, x^{(k_n)}$ are training examples assigned to group $m\\: \\mu_k$\n",
    "\n",
    "\n",
    "- If you have a cluster centroid with 0 points assigned to it, you can randomly re-initialize that centroid to a new point. You can also simply eliminate that cluster group.\n",
    "\n",
    "- After a number of iterations the algorithm will converge, where new iterations do not affect the clusters.\n",
    "\n",
    "Note on non-separated clusters: some datasets have no real inner separation or natural structure. K-means can still evenly segment your data into K subsets, so can still be useful in this case.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Optimization\n",
    "\n",
    "\n",
    "Recall some of the parameters we used in our algorithm:\n",
    "\n",
    "$c^{(i)}$ = index of cluster (1,2,...,K) to which example $x^{(i)}$is currently assigned\n",
    "\n",
    "$\\mu_k$ = cluster centroid k ($\\mu_k\\in$ $ℝ^n$)\n",
    "\n",
    "$\\mu_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned\n",
    "\n",
    "Using these variables, we can define **cost function**:\n",
    "\n",
    "$$J(c^{(i)},…,c^{(m)},μ_1​,…,μ_K​)=\\frac{1}{m}\\sum_{i=1}^{m}∣∣x{(i)}−μ_{c^{(i)}}​∣∣2$$\n",
    "\n",
    "We are trying to all our parameters. $min\\:_{c,μ}​ J(c,μ)$\n",
    "\n",
    "\n",
    "That is, we are finding all the values in sets c, representing all our clusters, and μ, representing all our centroids, that will minimize the **average of the distances** of every training example to its corresponding cluster centroid.\n",
    "\n",
    "The above cost function is often called the **distortion** of the training examples.\n",
    "\n",
    "In the **cluster assignment step**, our goal is to:\n",
    "\n",
    "- minimize $J(…)$ with $c^{(1)},\\dots,c^{(m)}$(holding $\\mu_1,\\dots,\\mu_K$ fixed)\n",
    "\n",
    "In the **move centroid step**, our goal is to:\n",
    "\n",
    "- Minimize J(…) with $mu_1,\\dots,\\mu_K$​\n",
    "\n",
    "With k-means, it is **not possible for the cost function to sometimes increase**. It should always descend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization\n",
    "\n",
    "There's one particular recommended method for randomly initializing your cluster centroids.\n",
    "\n",
    "- Have K<m. That is, make sure the number of your clusters is less than the number of your training examples.\n",
    "- Randomly pick K training examples, be sure the selected examples are unique\n",
    "- Set $\\mu_1,\\dots,\\mu_K$ equal to these K examples.\n",
    "\n",
    "K-means **can get stuck in local optima**. To decrease the chance of this happening, you can run the algorithm on many different random initializations.\n",
    "In cases where K<10 it is strongly recommended to run a loop of random initializations.\n",
    "\n",
    "```python\n",
    "for i = 1 to 100:\n",
    "   randomly initialize k-means\n",
    "   run k-means to get 'c' and 'm'\n",
    "   compute the cost function (distortion) J(c,m)\n",
    "pick the clustering that gave us the lowest cost\n",
    "\n",
    "```\n",
    "\n",
    "## Choosing the number of clusters \n",
    "\n",
    "Choosing K can be quite arbitrary and ambiguous.\n",
    "\n",
    "**The elbow method:** \n",
    "- plot the cost J and the number of clusters K. The cost function should reduce as we increase the number of clusters, and then flatten out. Choose K at the point where the cost function starts to flatten out.\n",
    "\n",
    "However, fairly often, the curve is **very gradual**, so there's no clear elbow.\n",
    "\n",
    "**Note**: J will **always** decrease as K is increased. The one exception is if k-means gets stuck at a bad local optimum.\n",
    "\n",
    "Another way to choose K is to observe how well k-means performs on a **downstream purpose**. \n",
    "- In other words, you choose K that proves to be most useful for some goal you're trying to achieve from using these clusters.\n",
    "    - for example: TBD\n",
    "\n",
    "Drawbacks of K-Means: \n",
    "\n",
    "http://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
